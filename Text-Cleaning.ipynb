{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ebef78e-373f-45b4-94b1-839d8706e7d5",
   "metadata": {},
   "source": [
    "# Una guía rápida para la limpieza de texto usando la biblioteca nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e72c2-9530-4a1d-b4ef-f8f16669803b",
   "metadata": {},
   "source": [
    "## Eliminando espacios extra\n",
    "<p>La mayoría de las veces, los datos de texto que tiene pueden contener espacios adicionales entre las palabras, después o antes de una oración. Entonces, para comenzar, eliminaremos estos espacios adicionales de cada oración usando expresiones regulares.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "383da1e8-56fb-4dea-b85a-aab5b9f4592e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP is an interesting field. \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "doc = \"NLP  is an interesting    field.  \"\n",
    "new_doc = re.sub(\"\\s+\",\" \", doc)\n",
    "print(new_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320f5b69-2c0a-42f4-aa0a-de1e87287907",
   "metadata": {},
   "source": [
    "## Eliminación de puntuaciones.\n",
    "<p>Las puntuaciones presentes en el texto no agregan valor a los datos. La puntuación, cuando se adjunta a cualquier palabra, creará un problema al diferenciar con otras palabras.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9da07a0e-c1a1-4a1f-99f7-8d5888f5a01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello How are you Im very excited that youre going for a trip to Europe Yayy'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hello! How are you!! I'm very excited that you're going for a trip to Europe!! Yayy!\"\n",
    "re.sub(\"[^-9A-Za-z ]\", \"\" , text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f61b0e-c619-4287-93ee-f41070121c94",
   "metadata": {},
   "source": [
    "## Normalización de casos\n",
    "<p>En esto, simplemente convertimos el caso de todos los caracteres en el texto a mayúsculas o minúsculas. Como python es un lenguaje que distingue entre mayúsculas y minúsculas, tratará a NLP y NLP de manera diferente. Uno puede convertir fácilmente la cadena a inferior o superior usando:\n",
    "<strong> str.inferior() o str.superior() </strong>.</p>\n",
    "\n",
    "<p>Por ejemplo, puede convertir el carácter a minúsculas o mayúsculas al momento de verificar los signos de puntuación.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfba9b2c-5674-4ed2-b0e0-5a5f966ab90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello how are you im very excited that youre going for a trip to europe yayy'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "text = \"Hello! How are you!! I'm very excited that you're going for a trip to Europe!! Yayy!\"\n",
    "text_clean = \"\".join([i.lower() for i in text if i not in string.punctuation])\n",
    "text_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fefe47-7ebf-4fea-b131-1a67e6e5828c",
   "metadata": {},
   "source": [
    "## Tokenization \n",
    "<p>Dividir una oración en palabras y crear una lista, es decir, cada oración es una lista de palabras. Existen principalmente 3 tipos de tokenizadores.</p>\n",
    "\n",
    "<p>a. word_tokenize: Es un tokenizador genérico que separa palabras y puntuaciones. Un apóstrofo no se considera como puntuación aquí.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3221790-a5b6-435b-b6c8-7b17fcdc9d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " '!',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '!',\n",
       " '!',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'very',\n",
       " 'excited',\n",
       " 'that',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'going',\n",
       " 'for',\n",
       " 'a',\n",
       " 'trip',\n",
       " 'to',\n",
       " 'Europe',\n",
       " '!',\n",
       " '!',\n",
       " 'Yayy',\n",
       " '!']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "text = \"Hello! How are you!! I'm very excited that you're going for a trip to Europe!! Yayy!\"\n",
    "nltk.tokenize.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db91a06-de4b-49aa-b4a7-0ae450ca8ba2",
   "metadata": {},
   "source": [
    "## regexp_tokenize\n",
    "<p>Se puede utilizar cuando queremos separar palabras de nuestro interés que siguen un patrón común\n",
    "como extraer todos los hashtags de tweets, direcciones de tweets o hipervínculos del texto.</p>\n",
    "<p>En esto, puede usar las funciones normales de expresiones regulares para separar las palabras.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a337fff-49af-43e2-b271-dc7466289f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What are your views related to US elections', 'nitin']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "a = 'What are your views related to US elections @nitin'\n",
    "re.split('\\s@', a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910a489e-9b94-4c31-b6b2-d74c25d80e5a",
   "metadata": {},
   "source": [
    "## Removing Stopwords\n",
    "<p>Las palabras vacías incluyen: I, he, she y, but, was were, being, have, etc., que no agregan significado a los datos.\n",
    "Por lo tanto, estas palabras deben eliminarse, lo que ayuda a reducir las características de nuestros datos. Estos se eliminan después de tokenizar el texto.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26bd6150-43ac-4d17-8a7c-0d44bd7b680c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello How are you Im very excited that youre going for a trip to Europe Yayy\n",
      "['Hello', 'How', 'are', 'you', 'Im', 'very', 'excited', 'that', 'youre', 'going', 'for', 'a', 'trip', 'to', 'Europe', 'Yayy']\n",
      "['Hello', 'How', 'Im', 'excited', 'youre', 'going', 'trip', 'Europe', 'Yayy']\n"
     ]
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "text = \"Hello! How are you!! I'm very excited that you're going for a trip to Europe!! Yayy!\"\n",
    "text_new = \"\".join([i for i in text if i not in string.punctuation])\n",
    "print(text_new)\n",
    "words = nltk.tokenize.word_tokenize(text_new)\n",
    "print(words)\n",
    "words_new = [i for i in words if i not in stopwords]\n",
    "print(words_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1012467-5875-46bc-9ad0-baae187d67e1",
   "metadata": {},
   "source": [
    "## Lemmatization & Stemming\n",
    "\n",
    "<p> una. Stemming: Una técnica que lleva la palabra a su forma raíz. Simplemente elimina los sufijos de las palabras.\n",
    "La palabra derivada puede no ser parte del diccionario, es decir, no necesariamente dará significado.\n",
    "Hay dos tipos principales de Stemmer: Porter Stemmer y Snow Ball Stemmer (versión avanzada de Porter Stemmer).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cb5c778-bb11-4fa8-a841-da8ed60a9de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'how', 'im', 'excit', 'your', 'go', 'trip', 'europ', 'yayi']\n"
     ]
    }
   ],
   "source": [
    "ps = nltk.PorterStemmer()\n",
    "w = [ps.stem(word) for word in words_new]\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38b20101-d8ab-4c20-aa12-ed9403b584b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'how', 'im', 'excit', 'your', 'go', 'trip', 'europ', 'yayi']\n"
     ]
    }
   ],
   "source": [
    "ss = nltk.SnowballStemmer(language = 'english')\n",
    "w = [ss.stem(word) for word in words_new]\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda12574-3f22-4bd8-af78-8c51f4d877e8",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "<p>Lleva la palabra a su forma raíz llamada Lema. Ayuda a llevar las palabras a su forma de diccionario. Se aplica a los sustantivos por defecto.\n",
    "Es más preciso ya que utiliza un análisis más informado para crear grupos de palabras con significados similares según el contexto.\n",
    "por lo que es complejo y lleva más tiempo. Esto se usa cuando necesitamos retener la información contextual.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a90b7ab-d960-4304-9e84-3c35c08e7945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'How', 'Im', 'excited', 'youre', 'going', 'trip', 'Europe', 'Yayy']\n"
     ]
    }
   ],
   "source": [
    "wn = nltk.WordNetLemmatizer()\n",
    "w = [wn.lemmatize(word) for word in words_new]\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c0b0ce-4ac2-4dba-aac1-fac2342dac09",
   "metadata": {},
   "source": [
    "## Notas finales\n",
    "<p> Estas son las técnicas de limpieza que se deben aplicar para que nuestros datos de texto estén listos para el análisis y la construcción de modelos. No es necesario que tengas que realizar todos estos pasos para la limpieza.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0429af5-ff91-4e83-99ca-0acdb6ce0aaf",
   "metadata": {},
   "source": [
    "Fuente: https://www.analyticsvidhya.com/blog/2020/11/text-cleaning-nltk-library/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
